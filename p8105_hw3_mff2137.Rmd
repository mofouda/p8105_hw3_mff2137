---
title: "p8105_hw3_mff2137"
author: "Mohammad Fouda"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

## Read in the data from `p8105.datasets`

```{r}
data("instacart")

instacart <-
  instacart %>% 
  as_tibble(instacart)
```

## Answers to the questions about the data

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, 
with each row resprenting a single product from an instacart order. Variables 
include identifiers for the user and the order as well as the order in which each
product was added to the cart and the product name. There are some order-related
variables such as time of the order, and number of days since prior order. In 
addition, there are variables about  the products such as name, department 
(e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits). In total, 
there are `r instacart %>% select(product_id) %>% distinct %>% count` products 
found in `r instacart %>% select(user_id, order_id) %>% distinct %>% count` orders
from `r instacart %>% select(user_id) %>% distinct %>% count` distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, 
there are 134 aisles, with fresh vegetables and fresh fruits holding the most 
items ordered by far.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Next is a plot that shows the number of items ordered in each aisle. Here, aisles
are ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))

```

Our next table shows the three most popular items in aisles `baking ingredients`,
`dog food care`, and `packaged vegetables fruits`, and includes the number of 
times each item is ordered in your table.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

Finally is a table showing the mean hour of the day at which Pink Lady Apples 
and Coffee Ice Cream are ordered on each day of the week. This table has been
formatted in an untidy manner for human readers. Pink Lady Apples are generally
purchased slightly earlier in the day than Coffee Ice Cream, with the exception
of day 5.

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  pivot_wider(
      names_from = order_dow, 
      values_from = mean_hour) %>%
  knitr::kable(digits = 2)
```

# Problem 2

## Importing and tidying the data

This code chunk imports and cleans the `accel_data` dataset, then switch it from
the wide to the long format to make it easier to manipulate, then, creates a new
variable `weekday_vs_weedend` to identify if the day the activity is measured falls
on a weekend or a weekday.  

```{r}
accel <-
    read.csv("data/accel_data.csv") %>% 
    janitor::clean_names() %>%
    pivot_longer(
        activity_1:activity_1440,
        names_to = "minute",
        values_to = "n_activities",
        names_prefix = "activity_"
        ) %>% 
    mutate(
        weekday_vs_weekend = if_else(
            day %in% c("Saturday", "Sunday"), "weekend", "weekday"),
        minute= as.integer(minute),
        day = factor(day))
```


## Answering questions about the data 

The resulting dataset has `r nrow(accel)` rows and 
`r ncol(accel)` columns. Some of the key variables include week, day identifier, 
the minute at which the activity is measured , and the number of activities at 
each minute of each day. There's also a variable that identifiers if the day on which 
activities are measured falls in a weekday vs a weekend.

Below is a code that aggregates across minutes and creates a total activities per 
day variable. Results are shown in the table, demonstrate a higher number of total 
activities in the last 3 weekdays (Wednesday through Friday).


```{r}
accel %>% 
    group_by(day) %>% 
    summarize(
        total_act = sum(n_activities)) %>% 
    arrange(total_act) %>% 
    knitr::kable()
```


Next, making a single-panel plot that shows the 24-hour activity time courses for
each day using color to indicate day of the week.

```{r}
accel %>% 
    filter(n_activities < 2500) %>%
    ggplot(aes(x = minute, y = n_activities, color = day)) + 
    geom_point(alpha = .7) +
    geom_smooth(se = FALSE) +
    labs(
    title = "Activity plot",
    x = "Minute of the day",
    y = "Number of activities",
    caption = "Data from CUMC") + 
  scale_x_continuous(
    breaks = c(250, 500, 750, 1000, 1250, 1500))
```

Alternatively, the plot below has the same variables and data but less crowded
which could be more informative. 

```{r}
accel %>% 
    filter(n_activities < 2500) %>% 
    ggplot(aes(x = minute, y = n_activities, color = day)) + 
    geom_smooth(se = FALSE) +
    labs(
    title = "Activity plot",
    x = "Minute of the day",
    y = "Number of activities",
    caption = "Data from CUMC") + 
  scale_x_continuous(
    breaks = c(250, 500, 750, 1000, 1250, 1500))
```

Based on the plots above shows that the number of activities tend to markedly 
increase around minute 250 in across all days then fluctuates as the day progress
while staying just above 200 activities, then a marked decrease around minute 1300 
of the day. While the data shows that number of activities is higher in certain 
days (Wednesday, Thursday, Friday), these patterns aligns with the normal activity
cycle expected along the day(i.e. increase in number during the day and early 
hours of the night and very low outside these times).

# Problem 3

## Read in data

```{r}
data("ny_noaa")

ny_noaa <-
  ny_noaa %>% 
  as_tibble(ny_noaa)
```

The `ny_noaa` dataset is a dataframe that has `r nrow(ny_noaa)` rows and 
`r ncol(ny_noaa)` columns. Some key variables include weather station identifiers,
date on which data was collected, variables showing the amount of precipitation 
(tenth of mm), and snow (mm) that fell, snow depth (mm), the maximum and minimum
temperatures (tenth of degree C). Each weather station may collect only a subset 
of these variables, the resulting dataset contains extensive missing data. The 
number of missing data is `r sum(is.na(ny_noaa))` 

## Cleaning and tidying the data

In this step, the variables `prcp:tmin` are converted to double for consistency. 
Then, the date is separated in to year, month, and day columns. Then, 
precipitation unit is changed to millimeter, maximum and minimum temperature 
unit is changed to degree C. 

```{r}
 noaa_tidy <-
   ny_noaa %>%
    separate(date, sep = "-", into = c("year", "month", "day")) %>% 
    mutate(across(.col = (c("year", "month", "day")), as.integer)) %>% 
    mutate(      
        prcp = as.double(prcp),
        snow = as.double(snow),
        snwd = as.double(snwd),
        tmax = as.double(tmax),
        tmin = as.double(tmin),
        month = month.name[month],
        prcp = prcp / 10,
        tmax = tmax / 10,
        tmin = tmin / 10) 
```

## Answering questions

For snowfall, 0 is the most commonly observed value since snowfall does not occur
most days of the year. 

```{r}
 noaa_tidy %>%
    group_by(snow) %>% 
    count(snow) %>% 
    arrange(desc(n))
```


## Average mamximum temperature plot


```{r}
 noaa_tidy %>%
    group_by(id, year, month) %>% 
    filter(month %in% c("January", "July")) %>% 
    drop_na() %>% 
    summarize(
        average_tmax = round(mean(tmax), 2)) %>% 
    ggplot(aes(x = year, y = average_tmax, color = id)) +
    geom_line(alpha = .5) +
    facet_grid(. ~ month) +
    theme(legend.position = "none") + 
    labs(
        title = "Average Maximum Temperature plot",
        x = "Year",
        y = "Average Maximum Temperature",
        caption = "Data from rnoaa") + 
    scale_x_continuous(
        breaks = c(1980, 1982, 1984, 1986, 1988, 1990,1992, 1994, 1996, 1998, 2000,
               2002, 2004, 2006, 2008, 2010)) +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

The average maximum temperature fluctuated across years but it remained between 
-10 and 10 C in January. Some January outliers include years 1982, 
1996 (less than -15 C) and 1997, 2006 (approx. 15 C). As for July, fluctuations 
were observed across years as well but generally remained between 20 and 32 C. 
July outliers include 1984 (just below 20 C), 1988 (below 15 C), 2020 (just below
35 C). 


